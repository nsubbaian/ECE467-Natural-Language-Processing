# ECE467-Natural-Language-Processing

## Part I: Conventional Statistical NLP

Topics: Course Introduction; Words, Morphology, and Tokenization; N-grams and Conventional Language Models; Part-of-Speech; Vector Space Models, Information Retrieval, and Text Categorization Tagging;

Suggested reading: Chapter 2, Chapter 3, Chapter 8,Chapter 4 and Sections 6.3 - 6.6 of Jurafsky and Martin

Programming Project #1

## Part II: Conventional Computational Linguistics

Topics:Phrase Structure Grammars and Dependency Grammars; Natural Languages and Psycholinguistics; Parsing; First-Order Logic and Semantics

Suggested reading: Chapter 12, Sections 15.1 - 15.2, Chapter 13, Chapter 14, Chapter 16  of Jurafsky and Martin

Programming Project #2

## Part III: Deep Learning and NLP

Topics: Feed-forward Neural Networks; Word Embeddings, Neural Language Models, and Word2vec; Recurrent Neural Networks, LSTMs, and GRUs; Encoder-Decoder Models, Attention, and Machine Translation; Advanced Topics

Suggested reading: Sections 7.1 - 7.4, Sections 6.8 - 6.10, Section 7.5, Chapter 9, Chapter 10   of Jurafsky and Martin

Programming Project #3

